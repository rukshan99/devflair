{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9bc4df3",
   "metadata": {},
   "source": [
    "# Personality Prediction Framework (v2.0)\n",
    "\n",
    "Developed by: R.T.R Jayasekara"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32844bb",
   "metadata": {},
   "source": [
    "## Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fdd8369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "727b2111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tune_sklearn import TuneGridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53acdbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4871ac40",
   "metadata": {},
   "source": [
    "## Preprocessor\n",
    "\n",
    "In order to work with text data, it is important to transform the raw text into a form that can be understood and used by Machine Learning algorithms, this is called preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8899d59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    status_data = pandas.read_csv(\"../datasets/mypersonality_final.csv\")\n",
    "\n",
    "    NEG_INDEX = 2\n",
    "    POS_INDEX = 3\n",
    "    NEU_INDEX = 4\n",
    "    COMP_INDEX = 5\n",
    "\n",
    "    # Annotate the status with sentiment scores\n",
    "    # From nltk.sentiment.vader corpus\n",
    "    if not os.path.isfile(\"../datasets/mypersonality_cleaned.csv\"):\n",
    "        status_data.insert(NEG_INDEX, \"sentiNEG\", 0)\n",
    "        status_data.insert(POS_INDEX, \"sentiPOS\", 0)\n",
    "        status_data.insert(NEU_INDEX, \"sentiNEU\", 0)\n",
    "        status_data.insert(COMP_INDEX, \"sentiCOMPOUND\", 0)\n",
    "\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "        count = 0\n",
    "        for row in status_data.itertuples():\n",
    "            \"\"\"\n",
    "            pos: positive\n",
    "            neg: negative\n",
    "            neu: neutral\n",
    "            compound: aggregated score for the sentence\n",
    "            \"\"\"\n",
    "            ss = sid.polarity_scores(row.STATUS)\n",
    "            status_data.iloc[count, NEG_INDEX] = ss[\"neg\"]\n",
    "            status_data.iloc[count, POS_INDEX] = ss[\"pos\"]\n",
    "            status_data.iloc[count, NEU_INDEX] = ss[\"neu\"]\n",
    "            status_data.iloc[count, COMP_INDEX] = ss[\"compound\"]\n",
    "            count += 1\n",
    "\n",
    "        status_data.to_csv(\"../datasets/mypersonality_cleaned.csv\")\n",
    "    else:\n",
    "        status_data = pandas.read_csv(\"../datasets/mypersonality_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78055eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NAs\n",
    "status_data = status_data.dropna()\n",
    "\n",
    "# We drop columns which give us a score for personality type\n",
    "status_data = status_data.drop(['STATUS', '#AUTHID', 'sEXT', 'sNEU', 'sAGR',\n",
    "                                    'sCON', 'sOPN', 'DATE'], axis=1)\n",
    "\n",
    "# Drop non-normalized scores of Brokerage and Betweenness\n",
    "status_data = status_data.drop(['BROKERAGE', 'BETWEENNESS', 'NBROKERAGE',\n",
    "                                    'NBETWEENNESS', 'DENSITY', 'TRANSITIVITY', 'NETWORKSIZE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cfc6316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentiNEG</th>\n",
       "      <th>sentiPOS</th>\n",
       "      <th>sentiNEU</th>\n",
       "      <th>sentiCOMPOUND</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.833</td>\n",
       "      <td>-0.3412</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.8916</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.759</td>\n",
       "      <td>-0.6249</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  sentiNEG  sentiPOS  sentiNEU  sentiCOMPOUND cEXT cNEU cAGR  \\\n",
       "0           0     0.000     0.412     0.588         0.4215    n    y    n   \n",
       "1           1     0.167     0.000     0.833        -0.3412    n    y    n   \n",
       "2           2     0.195     0.278     0.527         0.6280    n    y    n   \n",
       "3           3     0.000     0.259     0.741         0.4215    n    y    n   \n",
       "4           4     0.000     0.592     0.408         0.4404    n    y    n   \n",
       "5           5     0.000     0.000     1.000         0.0000    n    y    n   \n",
       "6           6     0.000     0.515     0.485         0.8916    n    y    n   \n",
       "7           7     0.000     0.000     1.000         0.0000    n    y    n   \n",
       "8           8     0.188     0.053     0.759        -0.6249    n    y    n   \n",
       "9           9     0.000     0.323     0.677         0.7351    n    y    n   \n",
       "\n",
       "  cCON cOPN  \n",
       "0    n    y  \n",
       "1    n    y  \n",
       "2    n    y  \n",
       "3    n    y  \n",
       "4    n    y  \n",
       "5    n    y  \n",
       "6    n    y  \n",
       "7    n    y  \n",
       "8    n    y  \n",
       "9    n    y  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8599f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the name of first row to \"rowID\"\n",
    "new_columns = status_data.columns.values\n",
    "new_columns[0] = \"rowID\"\n",
    "status_data.columns = new_columns\n",
    "\n",
    "# Put the columns to be predicted, at the end\n",
    "cols = status_data.columns.tolist()\n",
    "cols = cols[:5] + cols[5:10]\n",
    "status_data = status_data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7c95170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rowID</th>\n",
       "      <th>sentiNEG</th>\n",
       "      <th>sentiPOS</th>\n",
       "      <th>sentiNEU</th>\n",
       "      <th>sentiCOMPOUND</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.833</td>\n",
       "      <td>-0.3412</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.8916</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.759</td>\n",
       "      <td>-0.6249</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rowID  sentiNEG  sentiPOS  sentiNEU  sentiCOMPOUND cEXT cNEU cAGR cCON cOPN\n",
       "0      0     0.000     0.412     0.588         0.4215    n    y    n    n    y\n",
       "1      1     0.167     0.000     0.833        -0.3412    n    y    n    n    y\n",
       "2      2     0.195     0.278     0.527         0.6280    n    y    n    n    y\n",
       "3      3     0.000     0.259     0.741         0.4215    n    y    n    n    y\n",
       "4      4     0.000     0.592     0.408         0.4404    n    y    n    n    y\n",
       "5      5     0.000     0.000     1.000         0.0000    n    y    n    n    y\n",
       "6      6     0.000     0.515     0.485         0.8916    n    y    n    n    y\n",
       "7      7     0.000     0.000     1.000         0.0000    n    y    n    n    y\n",
       "8      8     0.188     0.053     0.759        -0.6249    n    y    n    n    y\n",
       "9      9     0.000     0.323     0.677         0.7351    n    y    n    n    y"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f095380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'y' for 1 and 'n' for 0\n",
    "features = ['cEXT', 'cNEU', 'cOPN', 'cAGR', 'cCON']\n",
    "for feature in features:\n",
    "    status_data[feature] = status_data[feature].map({'y': 1.0, 'n': 0.0}).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0688d14",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33c67ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test data: 66% and 33%\n",
    "train_data, test_data = train_test_split(status_data, test_size=0.50)\n",
    "\n",
    "train_OPN = train_data[['rowID','sentiNEG', 'sentiPOS', 'sentiNEU', 'sentiCOMPOUND', 'cOPN']].values\n",
    "train_CON = train_data[['rowID','sentiNEG', 'sentiPOS', 'sentiNEU', 'sentiCOMPOUND', 'cCON']].values\n",
    "train_EXT = train_data[['rowID','sentiNEG', 'sentiPOS', 'sentiNEU', 'sentiCOMPOUND', 'cEXT']].values\n",
    "train_AGR = train_data[['rowID','sentiNEG', 'sentiPOS', 'sentiNEU', 'sentiCOMPOUND', 'cAGR']].values\n",
    "train_NEU = train_data[['rowID','sentiNEG', 'sentiPOS', 'sentiNEU', 'sentiCOMPOUND', 'cNEU']].values\n",
    "\n",
    "test = test_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6cabc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2205    0\n",
       "3390    0\n",
       "2674    0\n",
       "3305    1\n",
       "3242    1\n",
       "       ..\n",
       "7324    0\n",
       "3454    0\n",
       "8652    0\n",
       "7034    0\n",
       "8856    0\n",
       "Name: cCON, Length: 4958, dtype: int32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.cCON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51d4e111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "def summarize_metrics(tp, tn, fp, fn):\n",
    "    precision = 0 if ((tp + fp) == 0) else (tp / (tp + fp))\n",
    "    recall = 0 if ((tp + fn) == 0) else (tp / (tp + fn))\n",
    "    accuracy = 0 if ((tp + tn + fp + fn) == 0) else ((tp + tn) / (tp + tn + fp + fn))\n",
    "    f1_score = 0 if ((recall + precision) == 0) else ((2 * recall * precision) / (recall + precision))\n",
    "\n",
    "    print(\"Precison:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 score:\", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50a91a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a confusion matrix\n",
    "def eval_model(rowID, result_df, trait):\n",
    "    tp_count = 0 #true-positive\n",
    "    tn_count = 0 #true-negative\n",
    "    fp_count = 0 #false-positive\n",
    "    fn_count = 0 #false-negative\n",
    "    \n",
    "    #print(result_df)\n",
    "    \n",
    "    for row in rowID:\n",
    "        test_trait_val = test_data.loc[test_data['rowID'] == row].cOPN\n",
    "        result_trait_val = result_df.loc[result_df['rowID'] == row].cOPN\n",
    "        \n",
    "        #check this if tree_______________________________________________________________________\n",
    "        if trait == 'cCON':\n",
    "            test_trait_val = test_data.loc[test_data['rowID'] == row].cCON\n",
    "            result_trait_val = result_df.loc[result_df['rowID'] == row].cCON\n",
    "        if trait == 'cEXT':\n",
    "            test_trait_val = test_data.loc[test_data['rowID'] == row].cEXT\n",
    "            result_trait_val = result_df.loc[result_df['rowID'] == row].cEXT\n",
    "        if trait == 'cAGR':\n",
    "            test_trait_val = test_data.loc[test_data['rowID'] == row].cAGR\n",
    "            result_trait_val = result_df.loc[result_df['rowID'] == row].cAGR\n",
    "        if trait == 'cNEU':\n",
    "            test_trait_val = test_data.loc[test_data['rowID'] == row].cNEU\n",
    "            result_trait_val = result_df.loc[result_df['rowID'] == row].cNEU\n",
    "        \n",
    "        if test_trait_val.astype(int).all() == 1:\n",
    "            if result_trait_val.astype(int).all() == 1:\n",
    "                tp_count += 1\n",
    "            else:\n",
    "                fn_count += 1\n",
    "        else:\n",
    "            if result_trait_val.astype(int).all() == 1:\n",
    "                fp_count += 1\n",
    "            else:\n",
    "                tn_count += 1\n",
    "\n",
    "    print(tp_count, tn_count, fp_count, fn_count)\n",
    "    summarize_metrics(tp_count, tn_count, fp_count, fn_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff0d3477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pipeline(rowID, result_df):\n",
    "    # Assess the model for Openness\n",
    "    print('Openness')\n",
    "    eval_model(rowID, result_df, 'cOPN')\n",
    "    print('\\n')\n",
    "    \n",
    "    # Assess the model for Conscientiousness\n",
    "    print('Conscientiousness')\n",
    "    eval_model(rowID, result_df, 'cCON')\n",
    "    print('\\n')\n",
    "    \n",
    "    # Assess the model for Extraversion\n",
    "    print('Extraversion')\n",
    "    eval_model(rowID, result_df, 'cEXT')\n",
    "    print('\\n')\n",
    "    \n",
    "    # Assess the model for Aggreableness\n",
    "    print('Aggreableness')\n",
    "    eval_model(rowID, result_df, 'cAGR')\n",
    "    print('\\n')\n",
    "\n",
    "    # Assess the model for Neuroticism\n",
    "    print('Neuroticism')\n",
    "    eval_model(rowID, result_df, 'cNEU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b3caf1",
   "metadata": {},
   "source": [
    "## Logistic Regression (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12ab2af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LR classifiers for each personality trait\n",
    "model_LR_OPN = LogisticRegression(solver = 'lbfgs')\n",
    "model_LR_OPN = model_LR_OPN.fit(train_OPN[0:, 1:5], train_OPN[0:, 5])\n",
    "\n",
    "model_LR_CON = LogisticRegression(solver = 'lbfgs')\n",
    "model_LR_CON = model_LR_CON.fit(train_CON[0:, 1:5], train_CON[0:, 5])\n",
    "\n",
    "model_LR_EXT = LogisticRegression(solver = 'lbfgs')\n",
    "model_LR_EXT = model_LR_EXT.fit(train_EXT[0:, 1:5], train_EXT[0:, 5])\n",
    "\n",
    "model_LR_AGR = LogisticRegression(solver = 'lbfgs')\n",
    "model_LR_AGR = model_LR_AGR.fit(train_AGR[0:, 1:5], train_AGR[0:, 5])\n",
    "\n",
    "model_LR_NEU = LogisticRegression(solver = 'lbfgs')\n",
    "model_LR_NEU = model_LR_NEU.fit(train_NEU[0:, 1:5], train_NEU[0:, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d4d27e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "output_LR_OPN = model_LR_OPN.predict(test[:, 1:5])\n",
    "output_LR_CON = model_LR_CON.predict(test[:, 1:5])\n",
    "output_LR_EXT = model_LR_EXT.predict(test[:, 1:5])\n",
    "output_LR_AGR = model_LR_AGR.predict(test[:, 1:5])\n",
    "output_LR_NEU = model_LR_NEU.predict(test[:, 1:5])\n",
    "\n",
    "rowID_LR = [TEST.rowID for TEST in test_data.itertuples()]\n",
    "\n",
    "result_df_LR = pandas.DataFrame({\"rowID\": rowID_LR,\"cOPN\": list(output_LR_OPN)})\n",
    "result_df_LR['cCON'] = list(output_LR_CON)\n",
    "result_df_LR['cEXT'] = list(output_LR_EXT)\n",
    "result_df_LR['cAGR'] = list(output_LR_AGR)\n",
    "result_df_LR['cNEU'] = list(output_LR_NEU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db392930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.0\n",
       "1       1.0\n",
       "2       1.0\n",
       "3       1.0\n",
       "4       1.0\n",
       "       ... \n",
       "4953    1.0\n",
       "4954    1.0\n",
       "4955    1.0\n",
       "4956    1.0\n",
       "4957    1.0\n",
       "Name: cOPN, Length: 4958, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_LR.cOPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c4e14c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openness\n",
      "3691 0 1267 0\n",
      "Precison: 0.7444534086325131\n",
      "Recall: 1.0\n",
      "Accuracy: 0.7444534086325131\n",
      "F1 score: 0.8535090761937796\n",
      "\n",
      "\n",
      "Conscientiousness\n",
      "48 2656 54 2200\n",
      "Precison: 0.47058823529411764\n",
      "Recall: 0.021352313167259787\n",
      "Accuracy: 0.54538120209762\n",
      "F1 score: 0.04085106382978724\n",
      "\n",
      "\n",
      "Extraversion\n",
      "0 2811 0 2147\n",
      "Precison: 0\n",
      "Recall: 0.0\n",
      "Accuracy: 0.5669624848729327\n",
      "F1 score: 0\n",
      "\n",
      "\n",
      "Aggreableness\n",
      "2629 0 2329 0\n",
      "Precison: 0.5302541347317467\n",
      "Recall: 1.0\n",
      "Accuracy: 0.5302541347317467\n",
      "F1 score: 0.6930275471200738\n",
      "\n",
      "\n",
      "Neuroticism\n",
      "0 3107 0 1851\n",
      "Precison: 0\n",
      "Recall: 0.0\n",
      "Accuracy: 0.626663977410246\n",
      "F1 score: 0\n"
     ]
    }
   ],
   "source": [
    "eval_pipeline(rowID_LR, result_df_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b15036",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc68f542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build KNN classifiers for each personality trait\n",
    "# k is chosen to be square root of number of training example\n",
    "model_KNN_OPN = KNeighborsClassifier(n_neighbors=250)\n",
    "model_KNN_OPN = model_KNN_OPN.fit(train_OPN[0:, 1:5], train_OPN[0:, 5])\n",
    "\n",
    "model_KNN_CON = KNeighborsClassifier(n_neighbors=250)\n",
    "model_KNN_CON = model_KNN_CON.fit(train_CON[0:, 1:5], train_CON[0:, 5])\n",
    "\n",
    "model_KNN_EXT = KNeighborsClassifier(n_neighbors=250)\n",
    "model_KNN_EXT = model_KNN_EXT.fit(train_EXT[0:, 1:5], train_EXT[0:, 5])\n",
    "\n",
    "model_KNN_AGR = KNeighborsClassifier(n_neighbors=250)\n",
    "model_KNN_AGR = model_KNN_AGR.fit(train_AGR[0:, 1:5], train_AGR[0:, 5])\n",
    "\n",
    "model_KNN_NEU = KNeighborsClassifier(n_neighbors=250)\n",
    "model_KNN_NEU = model_KNN_NEU.fit(train_NEU[0:, 1:5], train_NEU[0:, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3063bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "output_KNN_OPN = model_KNN_OPN.predict(test[:, 1:5])\n",
    "output_KNN_CON = model_KNN_CON.predict(test[:, 1:5])\n",
    "output_KNN_EXT = model_KNN_EXT.predict(test[:, 1:5])\n",
    "output_KNN_AGR = model_KNN_AGR.predict(test[:, 1:5])\n",
    "output_KNN_NEU = model_KNN_NEU.predict(test[:, 1:5])\n",
    "\n",
    "rowID_KNN = [TEST.rowID for TEST in test_data.itertuples()]\n",
    "\n",
    "result_df_KNN = pandas.DataFrame({\"rowID\": rowID_KNN,\"cOPN\": list(output_KNN_OPN)})\n",
    "result_df_KNN['cCON'] = list(output_KNN_CON)\n",
    "result_df_KNN['cEXT'] = list(output_KNN_EXT)\n",
    "result_df_KNN['cAGR'] = list(output_KNN_AGR)\n",
    "result_df_KNN['cNEU'] = list(output_KNN_NEU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38212bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openness\n",
      "3684 0 1274 0\n",
      "Precison: 0.7430415490116983\n",
      "Recall: 1.0\n",
      "Accuracy: 0.7430415490116983\n",
      "F1 score: 0.8525804211987966\n",
      "\n",
      "\n",
      "Conscientiousness\n",
      "249 2421 280 2008\n",
      "Precison: 0.4706994328922495\n",
      "Recall: 0.11032343819229065\n",
      "Accuracy: 0.5385235982250908\n",
      "F1 score: 0.17875089734386218\n",
      "\n",
      "\n",
      "Extraversion\n",
      "51 2800 71 2036\n",
      "Precison: 0.4180327868852459\n",
      "Recall: 0.024436990896023\n",
      "Accuracy: 0.5750302541347317\n",
      "F1 score: 0.04617473970122227\n",
      "\n",
      "\n",
      "Aggreableness\n",
      "2267 291 2068 332\n",
      "Precison: 0.522952710495963\n",
      "Recall: 0.8722585609849942\n",
      "Accuracy: 0.5159338442920532\n",
      "F1 score: 0.6538794346697433\n",
      "\n",
      "\n",
      "Neuroticism\n",
      "0 3089 0 1869\n",
      "Precison: 0\n",
      "Recall: 0.0\n",
      "Accuracy: 0.6230334812424365\n",
      "F1 score: 0\n"
     ]
    }
   ],
   "source": [
    "eval_pipeline(rowID_KNN, result_df_KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a9796e",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c2760ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build SVM classifiers for each personality trait\n",
    "model_SVM_OPN = SVC()\n",
    "model_SVM_OPN = model_SVM_OPN.fit(train_OPN[0:, 1:5], train_OPN[0:, 5])\n",
    "\n",
    "model_SVM_CON = SVC()\n",
    "model_SVM_CON = model_SVM_CON.fit(train_CON[0:, 1:5], train_CON[0:, 5])\n",
    "\n",
    "model_SVM_EXT = SVC()\n",
    "model_SVM_EXT = model_SVM_EXT.fit(train_EXT[0:, 1:5], train_EXT[0:, 5])\n",
    "\n",
    "model_SVM_AGR = SVC()\n",
    "model_SVM_AGR = model_SVM_AGR.fit(train_AGR[0:, 1:5], train_AGR[0:, 5])\n",
    "\n",
    "model_SVM_NEU = SVC()\n",
    "model_SVM_NEU = model_SVM_NEU.fit(train_NEU[0:, 1:5], train_NEU[0:, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fe09865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "output_SVM_OPN = model_SVM_OPN.predict(test[:, 1:5])\n",
    "output_SVM_CON = model_SVM_CON.predict(test[:, 1:5])\n",
    "output_SVM_EXT = model_SVM_EXT.predict(test[:, 1:5])\n",
    "output_SVM_AGR = model_SVM_AGR.predict(test[:, 1:5])\n",
    "output_SVM_NEU = model_SVM_NEU.predict(test[:, 1:5])\n",
    "\n",
    "rowID_SVM = [TEST.rowID for TEST in test_data.itertuples()]\n",
    "\n",
    "result_df_SVM = pandas.DataFrame({\"rowID\": rowID_SVM,\"cOPN\": list(output_SVM_OPN)})\n",
    "result_df_SVM['cCON'] = list(output_SVM_CON)\n",
    "result_df_SVM['cEXT'] = list(output_SVM_EXT)\n",
    "result_df_SVM['cAGR'] = list(output_SVM_AGR)\n",
    "result_df_SVM['cNEU'] = list(output_SVM_NEU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "391cef37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openness\n",
      "3684 0 1274 0\n",
      "Precison: 0.7430415490116983\n",
      "Recall: 1.0\n",
      "Accuracy: 0.7430415490116983\n",
      "F1 score: 0.8525804211987966\n",
      "\n",
      "\n",
      "Conscientiousness\n",
      "6 2691 10 2251\n",
      "Precison: 0.375\n",
      "Recall: 0.002658396101019052\n",
      "Accuracy: 0.5439693424768052\n",
      "F1 score: 0.005279366476022878\n",
      "\n",
      "\n",
      "Extraversion\n",
      "0 2871 0 2087\n",
      "Precison: 0\n",
      "Recall: 0.0\n",
      "Accuracy: 0.5790641387656313\n",
      "F1 score: 0\n",
      "\n",
      "\n",
      "Aggreableness\n",
      "2498 97 2262 101\n",
      "Precison: 0.5247899159663866\n",
      "Recall: 0.9611388995767602\n",
      "Accuracy: 0.5233965308592174\n",
      "F1 score: 0.6788965892104907\n",
      "\n",
      "\n",
      "Neuroticism\n",
      "0 3089 0 1869\n",
      "Precison: 0\n",
      "Recall: 0.0\n",
      "Accuracy: 0.6230334812424365\n",
      "F1 score: 0\n"
     ]
    }
   ],
   "source": [
    "eval_pipeline(rowID_SVM, result_df_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fe1962",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9add77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Naive Bayes classifiers for each personality trait\n",
    "model_GNB_OPN = GaussianNB()\n",
    "model_GNB_OPN = model_GNB_OPN.fit(train_OPN[0:, 1:5], train_OPN[0:, 5])\n",
    "\n",
    "model_GNB_CON = GaussianNB()\n",
    "model_GNB_CON = model_GNB_CON.fit(train_CON[0:, 1:5], train_CON[0:, 5])\n",
    "\n",
    "model_GNB_EXT = GaussianNB()\n",
    "model_GNB_EXT = model_GNB_EXT.fit(train_EXT[0:, 1:5], train_EXT[0:, 5])\n",
    "\n",
    "model_GNB_AGR = GaussianNB()\n",
    "model_GNB_AGR = model_GNB_AGR.fit(train_AGR[0:, 1:5], train_AGR[0:, 5])\n",
    "\n",
    "model_GNB_NEU = GaussianNB()\n",
    "model_GNB_NEU = model_GNB_NEU.fit(train_NEU[0:, 1:5], train_NEU[0:, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05d10ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "output_GNB_OPN = model_GNB_OPN.predict(test[:, 1:5])\n",
    "output_GNB_CON = model_GNB_CON.predict(test[:, 1:5])\n",
    "output_GNB_EXT = model_GNB_EXT.predict(test[:, 1:5])\n",
    "output_GNB_AGR = model_GNB_AGR.predict(test[:, 1:5])\n",
    "output_GNB_NEU = model_GNB_NEU.predict(test[:, 1:5])\n",
    "\n",
    "rowID_GNB = [TEST.rowID for TEST in test_data.itertuples()]\n",
    "\n",
    "result_df_GNB = pandas.DataFrame({\"rowID\": rowID_GNB,\"cOPN\": list(output_GNB_OPN)})\n",
    "result_df_GNB['cCON'] = list(output_GNB_CON)\n",
    "result_df_GNB['cEXT'] = list(output_GNB_EXT)\n",
    "result_df_GNB['cAGR'] = list(output_GNB_AGR)\n",
    "result_df_GNB['cNEU'] = list(output_GNB_NEU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e71390e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openness\n",
      "3684 0 1274 0\n",
      "Precison: 0.7430415490116983\n",
      "Recall: 1.0\n",
      "Accuracy: 0.7430415490116983\n",
      "F1 score: 0.8525804211987966\n",
      "\n",
      "\n",
      "Conscientiousness\n",
      "454 2138 563 1803\n",
      "Precison: 0.4464110127826942\n",
      "Recall: 0.20115197164377493\n",
      "Accuracy: 0.5227914481645825\n",
      "F1 score: 0.2773365913255956\n",
      "\n",
      "\n",
      "Extraversion\n",
      "401 2286 585 1686\n",
      "Precison: 0.4066937119675456\n",
      "Recall: 0.19214183037853377\n",
      "Accuracy: 0.5419524001613554\n",
      "F1 score: 0.2609827530100879\n",
      "\n",
      "\n",
      "Aggreableness\n",
      "1192 1374 985 1407\n",
      "Precison: 0.5475424896646761\n",
      "Recall: 0.458637937668334\n",
      "Accuracy: 0.5175473981444131\n",
      "F1 score: 0.4991624790619765\n",
      "\n",
      "\n",
      "Neuroticism\n",
      "144 2890 199 1725\n",
      "Precison: 0.4198250728862974\n",
      "Recall: 0.07704654895666131\n",
      "Accuracy: 0.6119402985074627\n",
      "F1 score: 0.1301989150090416\n"
     ]
    }
   ],
   "source": [
    "eval_pipeline(rowID_GNB, result_df_GNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5733cb6e",
   "metadata": {},
   "source": [
    "## Pickling the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65e6c249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling LR Models\n",
    "with open('pickle_files/ppf_lr_opn.pickle', 'wb') as files:\n",
    "  pickle.dump(model_LR_OPN, files)\n",
    "\n",
    "with open('pickle_files/ppf_lr_con.pickle', 'wb') as files:\n",
    "  pickle.dump(model_LR_CON, files)\n",
    "\n",
    "with open('pickle_files/ppf_lr_ext.pickle', 'wb') as files:\n",
    "  pickle.dump(model_LR_EXT, files)\n",
    "\n",
    "with open('pickle_files/ppf_lr_agr.pickle', 'wb') as files:\n",
    "  pickle.dump(model_LR_AGR, files)\n",
    "\n",
    "with open('pickle_files/ppf_lr_neu.pickle', 'wb') as files:\n",
    "  pickle.dump(model_LR_NEU, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6873f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling KNN Models\n",
    "with open('pickle_files/ppf_knn_opn.pickle', 'wb') as files:\n",
    "  pickle.dump(model_KNN_OPN, files)\n",
    "\n",
    "with open('pickle_files/ppf_knn_con.pickle', 'wb') as files:\n",
    "  pickle.dump(model_KNN_CON, files)\n",
    "\n",
    "with open('pickle_files/ppf_knn_ext.pickle', 'wb') as files:\n",
    "  pickle.dump(model_KNN_EXT, files)\n",
    "\n",
    "with open('pickle_files/ppf_knn_agr.pickle', 'wb') as files:\n",
    "  pickle.dump(model_KNN_AGR, files)\n",
    "\n",
    "with open('pickle_files/ppf_knn_neu.pickle', 'wb') as files:\n",
    "  pickle.dump(model_KNN_NEU, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f406a1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling SVM Models\n",
    "with open('pickle_files/ppf_svm_opn.pickle', 'wb') as files:\n",
    "  pickle.dump(model_SVM_OPN, files)\n",
    "\n",
    "with open('pickle_files/ppf_svm_con.pickle', 'wb') as files:\n",
    "  pickle.dump(model_SVM_CON, files)\n",
    "\n",
    "with open('pickle_files/ppf_svm_ext.pickle', 'wb') as files:\n",
    "  pickle.dump(model_SVM_EXT, files)\n",
    "\n",
    "with open('pickle_files/ppf_svm_agr.pickle', 'wb') as files:\n",
    "  pickle.dump(model_SVM_AGR, files)\n",
    "\n",
    "with open('pickle_files/ppf_svm_neu.pickle', 'wb') as files:\n",
    "  pickle.dump(model_SVM_NEU, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10e35811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling GNB Models\n",
    "with open('pickle_files/ppf_gnb_opn.pickle', 'wb') as files:\n",
    "  pickle.dump(model_GNB_OPN, files)\n",
    "\n",
    "with open('pickle_files/ppf_gnb_con.pickle', 'wb') as files:\n",
    "  pickle.dump(model_GNB_CON, files)\n",
    "\n",
    "with open('pickle_files/ppf_gnb_ext.pickle', 'wb') as files:\n",
    "  pickle.dump(model_GNB_EXT, files)\n",
    "\n",
    "with open('pickle_files/ppf_gnb_agr.pickle', 'wb') as files:\n",
    "  pickle.dump(model_GNB_AGR, files)\n",
    "\n",
    "with open('pickle_files/ppf_gnb_neu.pickle', 'wb') as files:\n",
    "  pickle.dump(model_GNB_NEU, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2252df38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
